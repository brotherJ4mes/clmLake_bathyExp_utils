#!/bin/Rscript
qlibrary(viridis)
qlibrary(stringr)
qlibrary(fields)


# settings (filter range)
#rng <- list(min=-25, max=50)
rng <- list(min=-25, max=50)
#lkmeta <- read.table('lake_ids.txt', head=T)
lkmeta <- read.csv('csv/lks_SA.csv', head=T) # surface areas generated by plot_depth.R
lkmeta <- lkmeta[order(lkmeta$name),]


min_frac <- .3
ctlcol <- 'brown'
glocol <- 'orange'




filter_rng <- function(data){
	sellow <- which(data < rng$min, arr.ind=T)
	selhig <- which(data > rng$max, arr.ind=T)
	data[sellow] <- NA
	data[selhig] <- NA
#	if(length(sellow) > 0) cat(sprintf('threw out %i low vals\n', length(sellow)))
#	if(length(selhig) > 0) cat(sprintf('threw out %i high vals\n', length(selhig)))
#	data[data<0] <- 0
	return(data)
}



calc_rmse <- function(mod, obs){ sqrt(mean((mod-obs)^2, na.rm=T)) }
calc_bias <- function(mod, obs){ mean(mod-obs, na.rm=T) }


obs <- read.table('txt/temp_out_mq3.txt')
frac <- read.table('txt/frac_out_mq3.txt')
obs[frac < min_frac] <- NA


dts_obs <- as.Date(row.names(obs), format='%Y%m%d')

ctl <- read.table('csv/ctl_T3D.csv', row.names=1)
glo <- read.table('csv/bi0m_T3D.csv', row.names=1)
glo2 <- read.table('csv/bi2m_T3D.csv', row.names=1)
dts_mod <- as.Date(row.names(ctl))
#glo2 <- read.table('bi2m_T3D.csv')


# filter for wild values
ctl <- filter_rng(ctl)
glo <- filter_rng(glo)
glo2 <- filter_rng(glo2)
obs <- filter_rng(obs)


lks <- names(obs)

ctl <-  ctl[!dts_mod < min(dts_obs),]
glo <-  glo[!dts_mod < min(dts_obs),]
glo2 <-  glo2[!dts_mod < min(dts_obs),]
dts <- dts_obs



rmse <- matrix(nrow=length(lks), ncol=3, dimnames=list(lks, c('ctl','glo','glo2')))
bias <- rmse

# PART 1:  PLOT AND SKILL ASSESS FULL TIME SERIES
for (lk in lks){
	if(all(is.na(obs[,lk]))) next
	# run skill
	rmse[lk, 'ctl'] <- calc_rmse(ctl[,lk], obs[,lk])
	rmse[lk, 'glo'] <- calc_rmse(glo[,lk], obs[,lk])
	rmse[lk, 'glo2'] <- calc_rmse(glo2[,lk], obs[,lk])
	bias[lk, 'ctl'] <- calc_bias(ctl[,lk], obs[,lk])
	bias[lk, 'glo'] <- calc_bias(glo[,lk], obs[,lk])
	bias[lk, 'glo2'] <- calc_bias(glo2[,lk], obs[,lk])
}



# generate table
deps <- read.table('txt/depths_by_lake.txt')[,-3]
#dep_diff <- -apply(deps, 1, diff)/deps[,'ctl']
#dep_diff <- -apply(deps, 1, diff)/deps[,'ctl']

tbl <- lkmeta[c('name','area_km')]
tbl$name <- str_to_title(gsub('_',' ',tbl$name))
tbl$dep_flt <- deps[,'ctl']
tbl$dep_glo <- deps[,'glo']

# alphabetize glo, ctl, and rmse, bias(unused)
ctl <- ctl[,order(names(ctl))]
glo <- glo[,order(names(glo))]
frac <- frac[,order(names(frac))]
rmse <- rmse[order(row.names(rmse)),]
bias <- bias[order(row.names(bias)),]


# intercomparison
tbl$rmsd <- apply(glo-ctl, 2, function(x) sqrt(mean(x^2, na.rm=T)))
rngdiff <- t(apply(glo-ctl, 2, function(x) range(x, na.rm=T)))
tbl$mindif <- rngdiff[,1]
tbl$maxdif <- rngdiff[,2]

# validation
tbl$frac <- apply(frac, 2, mean, na.rm=T)*100
tbl$rmse_diff <- apply(rmse[,c('ctl','glo')], 1, diff) # order of diff is UNINTUITIVE!

# remove lakes with no obs
#tbl <- tbl[is.finite(tbl$frac),]

# sort and calculate mean
#tbl <- tbl[order(tbl$rmse_diff, decreasing=T),]
tbl <- tbl[order(tbl$name),]
tbl$name <- gsub(' Lake', '', tbl$name)
tbl$name <- gsub('Mcconaugh', 'McConaugh', tbl$name)

tbl[nrow(tbl)+1,-1] <- apply(tbl[,-1], 2, mean, na.rm=T)
tbl[nrow(tbl),'name'] <- 'mean'
 




tbl$frac[is.na(tbl$frac)] <- 0
#tbl[tbl$name=='Great Salt Lake','dep_flt'] <- 0
#fmtstr='%15s, \t%4.0f,\t %1.0f,\t %1.0f,\t %3.0f,\t %4.2f,\t %3.1f,\t %3.1f\n'
#fmtstr='%15s,\t%4.0f,\t%1.0f,\t%1.0f,\t%3.0f,\t%4.2f,\t%3.1f,\t%3.1f\n'
fmtstr='%13s,\t%4.0f,\t%1.0f,\t%1.0f,\t%3.1f,\t%3.1f,\t%3.1f,\t%3.0f,\t%4.2f\n'
write(names(tbl), file='', sep=',\t', ncol=100)
cat(noquote(do.call('sprintf', c(fmtstr, tbl))))


